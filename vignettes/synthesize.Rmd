---
title: "Synthesize"
author: "Johan Sebastian Ohlendorff"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: ReferencesSynthesize.bib
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## Introduction

This vignette demonstrates how the function synthesize can be used to make an estimated lava object [@lava, see the next section] based on a formula in R. This can then be used to simulate data that should be similar to the data that we used to estimate the lava object with. There are 3 kinds of responses that can be used in the synthesize object:

- A survival-type response, i.e. either a response of the form `Surv(time,event)` or `Hist(time, event)`.
- A categorical response (for now only binary responses are supported corresponding to logistic regression).
- A normal/gaussian response. 

We first give a mathematical specification of the model assumed for the data:

### Introduction to the model
Assume first that we are not dealing with survival data. For a general input formula `y ~ x1 + ... + xk`, with `recursive = FALSE`, we assume the following model for the data $(Y_i,X_{1i},\dots, X_{ki})_{i=1, \dots n}$ (the observations are assumed iid). The response variable $Y$ is assumed to have a linear predictor $\eta ^T \bf{X}$ (either in the case of a logistic regression model or a linear model). The covariates $X_i$ are assumed to each have their own distribution, depending on the type of variable that they are. Continuous variables variables are assumed to be gaussian, i.e. if the $j$'th covariate is continuous then $X_j \sim N(\mu_j, \sigma^2_j)$ - with categorical/binary variables a similar assumption is made.

In the case of survival outcome data, we change the above setup to the data $(T_i, \Delta_i,X_{1i},\dots, X_{ki})_{i=1, \dots n}$ (this is assumed to be iid) where $T_i$ is the right-censored lifetime, $\Delta_i$ is the indicator telling us whether $T_i$ is uncensored or censored. Then the model is that the uncensored lifetime and censorship times follow a Weibull model (this is such that we can simulate survival data) with the same linear predictor as before. The covariates have also the same assumption as before. With competetive risks, a similar setup is made to this one.

With `recursive = TRUE`, we allow a type of structural equation models that states that we should also include the relationships with the covariates (indicating the corresponding formulas in R):
\begin{align*}
X_1 &\sim X_2 + \dots + X_k \\
X_2 &\sim X_3 + \dots + X_k \\
... \\
X_{k-1} &\sim X_k \\
\end{align*}

Synthesize then estimates these estimates by maximum likelihood estimation. We consider a few examples of our function. We first consider an example of the case where the response is a survival-type response. 

## Survival repsonse
We consider first the outcome survival case and load the Melanoma data set (please include all the variables in the data set in the model (otherwise synthesize might not work as intended)):
```{r}
library(riskRegression)
library(survival)
library(lava)
data("Melanoma")
Melanoma <- subset(Melanoma, select = c("time","status","thick","sex","age","invasion"))
knitr::kable(head(Melanoma))
```
The data concerns the survival of patients after an operation. We consider the variables of the dataset:
- `time` meaning the censored lifetime.
- `status` indicating whether the person died from the disease, 0 means censored, 1 means death by melanoma, and 2 means that the patient died from other causes. 
- `thick` meaning the thickness of the tumor (in mm).
- `sex` meaning the sex of the patient (M/F).
- `age` meaning the age of the patient at the time of operation.
- `invasion` meaning the level of invasion.

There are two kinds of survival responses we can consider; one with competing risks outcome and one without. We first consider how to use synthesize survival outcome, but the other case is the same; we just don't use the line below. In this case we need to make the event variable binary, i.e.
```{r}
Melanoma$eventBin <- 1*(Melanoma$status!=0)
```
corresponding to whether the patient survived (0) or not (1). Now we can synthesize a lava object (note that it is possible to specify how many unique values a variable can have to be considered either categorical or normal with `max.levels` (if not specified, it is 10)):
```{r}
ms <- synthesize(Surv(time,eventBin)~log(thick)+sex+age+invasion,data=Melanoma)
summary(ms)
```
In this case, a Weibull survival model is used to model the censorship time and uncensored lifetime with the given covariates. The model then specifies that the censored survival time and the indicator for wheher the data was censored or not is given deterministically. Under Exogeonous variables, we find the distributions for the covariates. Further down in "Regression parameters", we find the estimated parameters the regression (we note that the parameters for covariates are not as easily found). 

Let us consider a basic use case scenario where we simulate:
```{r}
set.seed(15)
d <- sim(ms,10000)
fit <- coxph(Surv(time,eventBin)~log(thick)+sex+age+invasion,data=Melanoma)
fit.s <- coxph(Surv(time,eventBin)~log(thick)+sex+age+invasion,data=d)

res <- as.data.frame(cbind(coef(fit),coef(fit.s)))
colnames(res) <- c("Model from original data", "Model from simulated data")
knitr::kable(res)
```
First we simulate from our estimated model, then we fit a corresponding model to the data and the simulated data. Hopefully the numbers between the 2 columns should be very similar which they are.

### Including recursion

If we specify that we want to have recursion then, we:
```{r}
ms.rec <- synthesize(Surv(time,eventBin)~log(thick)+sex+age+invasion,data=Melanoma,recursive = TRUE)
ms.rec
```
Here we see that (in the sense of formulas)
\begin{align*}
\verb|logthick| \ &\verb|~| \  \verb|sex + age + invasion| \\
\verb|sex| \ &\verb|~| \ \verb|age + invasion| \\
\verb|age| \ &\verb|~| \ \verb|invasion|
\end{align*}
 in addition to what we had before. We could simulate again:
```{r}
set.seed(15)
d <- sim(ms.rec,10000)
fit <- coxph(Surv(time,eventBin)~log(thick)+sex+age+invasion,data=Melanoma)
fit.s <- coxph(Surv(time,eventBin)~log(thick)+sex+age+invasion,data=d)

res <- as.data.frame(cbind(coef(fit),coef(fit.s)))
colnames(res) <- c("Model from original data", "Model from simulated data")
knitr::kable(res)
```

## A linear/logistic regression model
To make a simple linear regression model (the dataset `cars` is a included in R), we do:
```{r}
data(cars)
m.cars <- synthesize(dist ~ speed, data=cars)
summary(m.cars)
```
The cars dataset consists of a number of observations of the speed of cars and their stopping distances. Checking that the model makes sense is another matter, and we will not consider it here. This example is just to show that it is simple to use synthesize when the response variable is not of survival type, but we could simulate as before:
```{r}
set.seed(15)
d <- sim(m.cars,10000)
fit <- lm(dist ~ speed, data = cars)
fit.s <- lm(dist ~ speed, data = d)

res <- as.data.frame(cbind(coef(fit),coef(fit.s)))
colnames(res) <- c("Model from original data", "Model from simulated data")
knitr::kable(res)
```

Finally for a binary response, we could make a logistic regression which is done the same way as the linear regresion. We first find some data online suited for logistic regression:
```{r}
UCLA.dat <- read.csv("https://stats.idre.ucla.edu/stat/data/binary.csv")
knitr::kable(head(UCLA.dat))
```
The dataset has the variables:
- `admit` indicating whether a student was admitted as graduates to UCLA.
- `gre` indicating the students GRE score.
- `gpa` indicating what the student's grade point average was.
- `rank` indicating the rank of their undergraduate school.

A logistic regression could then try to model whether students were admitted by using the other variables in the dataset via:
```{r}
UCLA.syn <- synthesize(admit ~ gre + gpa + rank, data = UCLA.dat)
```
We could again make a simulation analysis similar to the ones before:
```{r}
set.seed(15)
d <- sim(UCLA.syn,10000)
fit <- glm(admit ~ gre + gpa + factor(rank), data = UCLA.dat)
fit.s <- glm(admit ~ gre + gpa + rank, data = d)

res <- as.data.frame(cbind(coef(fit),coef(fit.s)))
colnames(res) <- c("Model from original data", "Model from simulated data")
knitr::kable(res)
```

## References
